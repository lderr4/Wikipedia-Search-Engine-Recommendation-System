{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b75c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sknetwork\n",
    "from IPython.display import SVG\n",
    "from sknetwork.visualization import svg_graph, svg_bigraph\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "from sknetwork.utils import get_neighbors\n",
    "from sknetwork.ranking import PageRank, top_k, HITS\n",
    "from sknetwork.clustering import Louvain, get_modularity, PropagationClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikivitals = sknetwork.data.load_netset(\"wikivitals\") # load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e259213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wikivitals.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = wikivitals.adjacency # adjacency matrix\n",
    "names = wikivitals.names # article names\n",
    "labels = wikivitals.labels\n",
    "names_labels = wikivitals.names_labels\n",
    "biadjacency = wikivitals.biadjacency # biadjacency matrix (not used in project)\n",
    "print(wikivitals.keys())\n",
    "label_to_id = {name: i for i, name in enumerate(names_labels)}\n",
    "names[777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93278102",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12251b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(names)\n",
    "type(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4356e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank = PageRank()\n",
    "scores = pagerank.fit_predict(adjacency)\n",
    "for i in top_k(scores, 20):\n",
    "    print(names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cfff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = HITS()\n",
    "hubs = hits.fit_predict(biadjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d333e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [scores] # put page rank and HITS output into the same array\n",
    "scores.append(hubs)\n",
    "scores = np.array(scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b3dbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests # make wikipedia api request\n",
    "import tabulate # display output in pretty table\n",
    "from IPython.core.display import display, HTML # for converting html table to pretty table\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def format_link(title):\n",
    "    # Hipparcus -> https://en.wikipedia.org/wiki/Hipparchus\n",
    "    title = title.replace(\" \", \"_\")\n",
    "    return 'https://en.wikipedia.org/wiki/' + title\n",
    "\n",
    "def get_table(candidate_scores): # generate the html table that is displayed\n",
    "    \n",
    "    # candidate_scores: {title: (pagerank, hubs, incoming, outgoing)}\n",
    "    index_to_name = {-1: -1}\n",
    "    headers = [\"Index\", \"Title\", \"Link\", \"Incoming Links\", \"Outgoing Links\",\"PageRank\", \"Hubs\"]\n",
    "    table = []\n",
    "    for i,title in enumerate(candidate_scores):\n",
    "        row = []\n",
    "        row.append(i)\n",
    "        row.append(title)\n",
    "        row.append(format_link(title))\n",
    "        row.append(candidate_scores[title][2])\n",
    "        row.append(candidate_scores[title][3])\n",
    "        row.append(candidate_scores[title][0])\n",
    "        row.append(candidate_scores[title][1])\n",
    "        table.append(row)\n",
    "        index_to_name[i] = title\n",
    "        \n",
    "    return tabulate.tabulate(table, tablefmt='html', headers=headers , showindex=False), index_to_name\n",
    "        \n",
    "\n",
    "def search(query, scores, adjacency):\n",
    "    url = 'https://en.wikipedia.org/w/api.php'\n",
    "    params = {\n",
    "                    'action':'query',\n",
    "                    'format':'json',\n",
    "                    'list':'search',\n",
    "                    'utf8':1,\n",
    "                    'srsearch':query,\n",
    "                    'srlimit': 500,\n",
    "                    'srqiprofile': 'empty' # dont want assistance from wikipedia search engine\n",
    "                }\n",
    "    params['srsearch'] = query\n",
    "    data = requests.get(url, params=params).json() # api call with srsearch\n",
    "\n",
    "    candidates = []\n",
    "    for article in data['query']['search']:\n",
    "        if article['title'] in names:\n",
    "            candidates.append(article['title'])\n",
    "    \n",
    "    # row outgoing, col incoming\n",
    "    candidate_metrics = {} # {name: (pagerank, hubs , incoming, outgooing)}\n",
    "    for candidate in candidates:\n",
    "        i = names.index(candidate)\n",
    "        pagerank, hubs = scores[i][0], scores[i][1]\n",
    "        outgoing = np.sum(adjacency[i]) # row\n",
    "        incoming = np.sum(adjacency[:,i]) # col\n",
    "        candidate_metrics[candidate] = (pagerank, hubs, incoming, outgoing) \n",
    "        \n",
    "    candidate_metrics = dict(sorted(candidate_metrics.items(), key=lambda item: item[1][0], reverse=True)) # Put scores in descending order\n",
    "\n",
    "    return get_table(candidate_metrics) # generate a table with the metrics and labels\n",
    "\n",
    "def query(): # function to accept user input and call the search function\n",
    "    query = input(\"Enter your Search Query:\")\n",
    "    table, index_to_name = search(query, scores, adjacency)\n",
    "    display(table)\n",
    "    option = int(input(\"Enter Index to get more information about an article or '-1' to enter another query:\"))\n",
    "    \n",
    "    while option not in index_to_name.keys():\n",
    "        option = int(input(\"Invalid Option: Enter Index to get more information about an article or '-1' to enter another query:\"))\n",
    "        \n",
    "    return index_to_name[option]\n",
    "        \n",
    "\n",
    "def showArticle(name): # function to pull article abstract with wikipedia API\n",
    "    url = 'https://en.wikipedia.org/w/api.php'\n",
    "    params = {\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'titles': name,\n",
    "            'prop': 'extracts',\n",
    "            'exintro': True,\n",
    "            'explaintext': True,\n",
    "        }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    page = next(iter(data['query']['pages'].values()))\n",
    "    print(page['extract'])\n",
    "\n",
    "def menu(name): # Show menu when selecting an article\n",
    "    print(\"You have selected:\", name)\n",
    "    print(\"What would you like to do?\")\n",
    "    print(\"1. Read Article Abstract\")\n",
    "    print(\"2. See Recommended Articles\")\n",
    "    print(\"3. See All Incoming Articles\")\n",
    "    print(\"4. See All Outgoing Articles\")\n",
    "    print(\"5. Enter Another Query\")\n",
    "    print(\"6. Exit Program\")\n",
    "    option = int(input(\"Choose Here\"))\n",
    "    return option\n",
    "\n",
    "# outgoing = np.sum(adjacency[i]) # row\n",
    "# incoming = np.sum(adjacency[:,i]) # col\n",
    "\n",
    "def show_incoming(name): # showing incoming articles\n",
    "    \n",
    "    article_id = names.index(name)\n",
    "    col = adjacency[:,article_id].toarray()\n",
    "    incoming_ids = np.where(col == True)[0]\n",
    "    \n",
    "        # row outgoing, col incoming\n",
    "    metrics = {} # {name: (pagerank, hubs , incoming, outgooing)}\n",
    "    for i in incoming_ids:\n",
    "        name = names[i]\n",
    "        pagerank, hubs = scores[i][0], scores[i][1]\n",
    "        outgoing = np.sum(adjacency[i]) # row\n",
    "        incoming = np.sum(adjacency[:,i]) # col\n",
    "        metrics[name] = (pagerank, hubs, incoming, outgoing) \n",
    "        \n",
    "    metrics = dict(sorted(metrics.items(), key=lambda item: item[1][0], reverse=True)) # Put scores in descending order\n",
    "    table, index_to_name = get_table(metrics)\n",
    "    display(table)\n",
    "    option = int(input(\"Enter Index to get more information about an article or '-1' to enter another query:\"))\n",
    "    \n",
    "    while option not in index_to_name.keys():\n",
    "        option = int(input(\"Invalid Option: Enter Index to get more information about an article or '-1' to enter another query:\"))\n",
    "        \n",
    "    return index_to_name[option]\n",
    "    \n",
    "    \n",
    "\n",
    "def show_outgoing(name): # show outgoing articles\n",
    "    article_id = names.index(name)\n",
    "    row = adjacency[article_id].toarray()[0]\n",
    "    outgoing_ids = np.where(row == True)[0]\n",
    "    metrics = {} # {name: (pagerank, hubs , incoming, outgooing)}\n",
    "    for i in outgoing_ids:\n",
    "        name = names[i]\n",
    "        pagerank, hubs = scores[i][0], scores[i][1]\n",
    "        outgoing = np.sum(adjacency[i]) # row\n",
    "        incoming = np.sum(adjacency[:,i]) # col\n",
    "        metrics[name] = (pagerank, hubs, incoming, outgoing) \n",
    "        \n",
    "    metrics = dict(sorted(metrics.items(), key=lambda item: item[1][0], reverse=True)) # Put scores in descending order\n",
    "    table, index_to_name = get_table(metrics)\n",
    "    display(table)\n",
    "    option = int(input(\"Enter Index to get more information about an article or '-1' to enter another query:\"))\n",
    "    \n",
    "    while option not in index_to_name.keys():\n",
    "        option = int(input(\"Invalid Option: Enter Index to get more information about an article or '-1' to enter another query:\"))\n",
    "        \n",
    "    return index_to_name[option]\n",
    "\n",
    "def get_recommendations(name): # recommendation algorithm\n",
    "    \n",
    "    index = names.index(name)\n",
    "    label = labels[index]\n",
    "    \n",
    "    \n",
    "    cluster_indices = np.where(labels == label)[0]\n",
    "    weights = labels == label\n",
    "    \n",
    "    weight = 1 / np.sum(weights) # weight for articles in cluster\n",
    "    \n",
    "    weights = { i: weight for i in cluster_indices }\n",
    "    weights[index] = 3 # weight for article to be recommended\n",
    "    \n",
    "    pagerank = PageRank()\n",
    "    scores_clust = pagerank.fit_transform(adjacency, weights) # get pagerank scores within the cluster\n",
    "    \n",
    "    rec = top_k(scores_clust - scores[:,0], 100) # difference between original pagerank score and current score\n",
    "    rec = np.delete(rec, np.where(rec == index)) # remove the thing that is getting recommended\n",
    "    rec = np.array([i for i in rec if i in cluster_indices]) # remove recommendations not in cluster\n",
    "    \n",
    "    \n",
    "    metrics = {} # {name: (pagerank, hubs , incoming, outgooing)}\n",
    "    for i in rec[:20]:\n",
    "        name = names[i]\n",
    "        pagerank, hubs = scores[i][0], scores[i][1]\n",
    "        outgoing = np.sum(adjacency[i]) # row\n",
    "        incoming = np.sum(adjacency[:,i]) # col\n",
    "        metrics[name] = (pagerank, hubs, incoming, outgoing) \n",
    "        \n",
    "    table, index_to_name = get_table(metrics)\n",
    "    display(table)\n",
    "    option = int(input(\"Enter Index to get more information about an article or '-1' to enter another query:\"))\n",
    "    \n",
    "    while option not in index_to_name.keys():\n",
    "        option = int(input(\"Invalid Option: Enter Index to get more information about an article or '-1' to enter another query:\"))\n",
    "        \n",
    "    return index_to_name[option]\n",
    "    \n",
    "def main(): # driver function\n",
    "    name = query()\n",
    "    while True:\n",
    "        if name == -1:\n",
    "            name = query()\n",
    "        else:\n",
    "            while True:\n",
    "                menu_choice = menu(name)\n",
    "                if menu_choice == 1:\n",
    "                    showArticle(name)\n",
    "\n",
    "                elif menu_choice == 2:\n",
    "                    name = get_recommendations(name)\n",
    "   \n",
    "                elif menu_choice == 3:\n",
    "                    name = show_incoming(name)\n",
    "\n",
    "                elif menu_choice == 4:\n",
    "                    name = show_outgoing(name)\n",
    "\n",
    "                elif menu_choice == 5:\n",
    "                    name = query()\n",
    "                    break\n",
    "\n",
    "                elif menu_choice == 6:\n",
    "                    return\n",
    "            \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6579306",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Louvain\n",
    "resolutions = np.linspace(0.1, 3, 30)\n",
    "\n",
    "modularities = ['Dugue', 'Newman', 'Potts']\n",
    "best = {\"mod\": None, \"res\": None, \"score\":0}\n",
    "\n",
    "dugue = []\n",
    "newman = []\n",
    "potts = []\n",
    "\n",
    "for mod in modularities:\n",
    "    for res in resolutions:\n",
    "        \n",
    "        lv = Louvain(resolution=res, modularity=mod)\n",
    "        lv.fit(adjacency)\n",
    "        lv_labels = np.array(lv.labels_)\n",
    "        lv_score = get_modularity(adjacency, lv_labels)\n",
    "        \n",
    "        if lv_score > best[\"score\"]:\n",
    "            best[\"mod\"]=mod\n",
    "            best[\"res\"]=res\n",
    "            best[\"score\"]=lv_score\n",
    "            \n",
    "        if mod == \"Dugue\":\n",
    "            dugue.append(lv_score)\n",
    "        elif mod == \"Newman\":\n",
    "            newman.append(lv_score)\n",
    "        elif mod == \"Potts\":\n",
    "            potts.append(lv_score)\n",
    "\n",
    "            \n",
    "            \n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_louv = Louvain(resolution=best['res'], modularity=best[\"mod\"])\n",
    "best_louv.fit(adjacency)\n",
    "np.unique(best_louv.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning plot for Louvain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best={'mod': 'Dugue', 'res': 1.0999999999999999, 'score': 0.4721801809672379}\n",
    "\n",
    "# plot the lines\n",
    "plt.plot(resolutions, dugue, label='Dugue')\n",
    "plt.plot(resolutions, potts, label='Potts')\n",
    "plt.plot(resolutions, newman, label='Newman')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.xlabel('Resolution')\n",
    "plt.ylabel('Modularity Score')\n",
    "plt.title('Parameter Tuning of Louvain Clustering')\n",
    "\n",
    "\n",
    "plt.savefig('louvain.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca25780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sknetwork.embedding import Spectral \n",
    "\n",
    "num_components = 25\n",
    "spectral = Spectral(num_components)\n",
    "embedding = spectral.fit_transform(adjacency)\n",
    "\n",
    "print(embedding[7777])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check for Louvain\n",
    "labels = best_louv.labels_\n",
    "clusters = []\n",
    "for label in np.unique(labels): # loop through each cluster label\n",
    "    cluster_indices = np.where(labels==label)[0]\n",
    "    \n",
    "    # [{index: (pr, hubs), index: (pr, hubs)}, {index: (pr, hubs), index: (pr, hubs)}]\n",
    "    indice_to_score = {i: (scores[i][0], scores[i][1]) for i in cluster_indices} \n",
    "    clusters.append(indice_to_score) \n",
    "    \n",
    "for cluster in clusters:\n",
    "    \n",
    "    sorted_cluster = dict(sorted(cluster.items(), key=lambda x: x[1][0], reverse=True))\n",
    "    sorted_indices = list(sorted_cluster.keys())\n",
    "    for i in sorted_indices[:30]:\n",
    "        print(names[i] , scores[i])\n",
    "    print(\"------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f296b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage # this cell generates a dendrogram, not used in report\n",
    "from sknetwork.visualization import svg_dendrogram\n",
    "\n",
    "labels = best_louv.labels_\n",
    "clusters = []\n",
    "for label in np.unique(labels):\n",
    "    cluster_indices = np.where(labels==label)[0]\n",
    "    \n",
    "    \n",
    "label = 4\n",
    "index = selection[label] # selection : [[top k articles cluster 0 by index], [top k articles cluster 1 by index], etc ]\n",
    "print(index)\n",
    "print(len(index))\n",
    "\n",
    "dendrogram_articles = linkage(embedding[index], method='ward')\n",
    "image = svg_dendrogram(dendrogram_articles, names=names[index], rotate=True, width=200, scale=2, n_clusters=4)\n",
    "SVG(image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee011f03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc5fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
